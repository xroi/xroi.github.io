---
cssclasses:
  - rtl-class
---

## 1 - מבוא

##### מונחים
- ***זמן תגובה:*** הזמן מהרגע שרוצים שעבודה תתחיל עד שהיא מסיימת.
- נוסחא: $Overhead + Utilization = CPU usage$.
- $$ Slowdown = \frac{ResponseTime}{RunTime(isolated)} $$
- ***מולטיפרוגרמניג:*** כשיש כמה תכניות בזיכרון שמחליפים ביניהן.
- ***חלוקת זמן/Time Sharing:*** נגיד כשתכנית עושה פעולת IO אז עושים קונטקסט סוויטצ' לתכנית אחרת.
- **ה-Scheduler:*** משהו במערכת ההפעלה שקובע איזו תכנית רצה כרגע ומתי היא תוחלף.
- ***מקבול:*** הרצת מספר תכניות במקביל על ליבות CPU שונות.      

##### מבנה
- אנו מניחים כי רכיבים פריפריילים במחשב (כמו SSD, מדפסת) יכולים לגשת לזיכרון באמצעות **Direct Memory Access (DMA)** כלומר בלי לערב את ה-CPU.

---
## 2 - מצב Kernel ו-Interrupts
##### מונחים
- ***קריאת מערכת/System Call:*** קריאה של תהליך לפונקציה שמסופקת על ידי מערכת ההפעלה ונותנת שירות כלשהו. (לדוגמא קריאת קובץ).
- ***פקודות פריבילגיות/Privileged Instructions:*** פקודות שאפשר להריץ רק ב-Kernel Mode.
- ***קרנל מוד/Kernel Mode:*** מצב של ה-CPU שמאפשר לו להריץ פקודות פריבלגיות.
- ***יוזר מוד/User Mode:*** המצב הרגיל של ה-CPU שלא מאפשר פקודות פריבילגיות.
- ***מוד ביט/Mode Bit:*** ביט שקובע אם נמצאים בקרנל מוד או יוזר מוד. אפשר לשנות אותו רק בקרנל מוד.
- ***טראפ/Trap:*** מעבר מיוזר מוד לקרנל מוד.
- ***שכבות של המערכת***
- ***דרייברים***
- ***פסיקות/אינטרפטים/Interrupts:***  נשלחים על ידי ה-Controllers (סוג של מעבד קטן) של הרכיבים הפריפריאלים. הקונטרולרים הם אלו שכותבים ב-DMA לזיכרון. גם Traps ו-Exceptions הם אינטרפטים! לכל סוג של Exception יש קוד אחר ועל כן אינטרפט הנדלר אחר. כנ"ל האינטרפט הנדלר של הTrap הוא זה שמבצע אותו.
- ***ווקטור אינטרפטים:*** האינדקס זה ה-ID של האיטרפט (לדוגמא 7 - עכבר, 15 - מקלדת) והערך הוא הכתובת של ה**Interrupt Handler**.
-
##### מבנה
- מעבר מקרנל מוד ליוזר מוד נקרא ***Trap***.

---
## 3 - תהליכים ות'רדים
- לכל תהליך יש ***קונטקסט***, המוגדר על ידי ערכי הרגיסטרים במעבד, המידע של התכנית בזיכרון ומטאדאטא על התכנית בזיכרון (גם המוד ביט בקונטקסט!).
- ***פרוסס קונטרול בלוק/PCB/Process Control Block:*** בלוק מידע שנשמר בזיכרון הקרנל (שניתן לגשת אליו רק בקרנל מוד), ומייצג את התהליך. מכיל את ה-ID של התהליך, מטא דאטא עליו (לדוגמא הסטייט שלו (רץ או מחכה)), מידע על התליך (Base + Bound, אילו קבצים פתוחים) וסנאפשוט של הרג'יסטרים של ה-CPU.
	- כשעושים קונטקסט סוויץ' מעדכנים את ה-PCB בזיכרון.
- ***המתזמן/Scheduler:*** קובע איזו תכנית תרוץ על ה-CPU ולמשך כמה זמן.
- ***ה-Dispatcher:*** המודול שאחראי על ביצוע ההחלטות של המתזמן (קונטקסט סוויץ').
- ***קריאת המערכת Fork:*** מאפשרת לתהליך לשכפל את עצמו על ידי העתקה של ה-PCB. הפונקציה מחזירה 0 עבור האב ואת ה-pid (שונה מ-0) של הילדים. תהליכים forked יכולים לתקשר אחד עם השני רק דרך מערכת ה-Inter Process Communication (IPC) אבל יש לה אוברהד גבוה ובעיות סנכרון.
- ***ת'רדים/Threads:*** מאפשרים לתהליך אחד ללכת בנתיבי ביצוע שונים. לכל הת'רדים משותף הקוד, ה-Heap והקבצים הפתוחים, אבל לכל אחד יש סטאק משלו (אבל למרות זאת גם הסטאקים חולקים את אותו מרחב כתובות וירטואלי (פשוט נמצאים בו במקומות אחרים!)).
	- ***קרנל ת'רד:*** הניהול מתבצע על ידי הקרנל של ה-OS. (יש ב-PCB רשימה של פוניטרים לדסקריפטורים של הת'רדים (Thread Control Block - TCB) שנמצאים בזיכרון קרנל)
	- ***יוזר ת'רד:*** הניהול מתבצע על ידי המשתמש ביוזר מוד. (כל הדסקריפטורים של הת'רדים בהיפ) מערכת ההפעלה לא מודעת לקיום של הת'רדים האלה.
	- יש טבלה יפה בסיכום הרצאה 3 על ההבדלים בין תהליך, קרנל ת'רד ויוזר ת'רד.

##### פקודות
```c
pid = fork()
int kill(pid_t pid, int sig) / Kill [OPTION] pid

// Declaring a new action for a program given a signal
int sigaction(int sig, struct sigaction *new_act, struct sigaction *old_act)

// Wait unil recieving a signal
pause()

// add/remove/change current signal mask
sigprocmask(int how, const sigset_t *set, sigset_t *oldset)

// save and long CPU registers (for implementing user level threads)
sigsetjmp(sigjmp_buf env, int savesigs)
siglongjmp(sigjmp_buf env, int val)

###########
# Threads #
###########

// Create a new thread
int pthread_create(pthread_t *thread, const pthread_attr_t *attr=NULL, void *(*start_routine) (void *), void *arg)
// Terminate current Thread
pthread_exit(void *status)
// Cancel other thread
pthread_cancel(pthread_t thread)
// Wait for other thread to terminate on it's own
int pthread_join(pthread_t thread, void **ret_val)

#########
# Mutex #
#########

// Initializing a mutex
pthread_mutex_t mymutex = PTHREAD_MUTEX_INITIALIZER;
OR pthread_mutex_init(mutex, attr)
// Detroying mutex 
pthread_mutex_destroy(mutex)
// Locking mutex
pthread_mutex_lock(*mutex)
// Unlocking mutex
pthread_mutex_unlcok(*mutex)

###########
# Monitor #
###########
//todo recit 4

#############
# Semaphore #
#############
// Initializing a semaphore
int sem_init(sem_t *sem, int pshared, unsigned int value)
// Decrementing semphore
int sem_wait(sem_t *sem)
// Incrementing semaphore
int sem_post(sem_t *sem)

```

 ---
## 4 - סנכרון
- ***איזור קריטי/Critical Section:*** נרצה ששני תהליכים/ת'רדים שונים לא יהיו בו בו זמנית.
- מה חשוב באלגוריתמי מוטואל אקסקלוז'ן:
	1. מוטואל אקסקלוז'ן/Mutual Exclusion: לא יהיו שני תהליכים בקטע הקריטי בו זמנית.
	2. התקדמות/Progress: אם קיים תהליך שמנסה להיכנס לקטע הקריטי, אז בסופו של דבר תהליך **כלשהו** יכנס לקטע הקריטי.
	3. מניעת הרעבה/Starvation Freedom: אם קיים תהליך שמנסה להיכנס לקטע הקריטי, אז בסופו של דבר **הוא** יכנס לקטע הקריטי.
	4. כלליות: האלגוריתם לא מניח שום דבר על מספר המשתתפים וכדומה.
	5. בלי חסימה ב-Remainder: שום תהליך מחוץ לקטע הקריטי (או ל-Entry/Exit Codes) לא יחסום תהליך אחר.
- ***רייס קונדישן/Race Condition:*** כאשר התזמון של ת'רדים משנה את התוצאה הסופיתץ
- ***פעולה אטומית:*** פעולה שמתבצעת בסייקל CPU אחד (אז לא יכול לקרות קונטקסט סוויץ' באמצע)
- ***ביזי ווייטינג/Busy Wating:*** כאשר תהליך מחכה למשהו בלולאה (מבזבז CPU).
- פעולות אטומיות מורכבות:
	- Test&Set
	- Fetch&Add
	- Compare&Swap
- ***סמפור/Semaphore:*** דאטא טייפ שמסופק על ידי ספריות, ומונע Busy Waiting ומאפשר לממש Mutual Exclusion בקלות, עם הפעולות Init(S,v), Down(S), Up(S) שמתבצעות באופן אטומי. מאפשר ל-v ת'רדים להיכנס בו זמנית וכך זה במידה מסוימת מכליל מיוטקס.
- ***מיוטקס:*** דאטא טייפ עם הפעולות Lock(S), Unlock(S), Init(S), מאפשר רק לת'רד אחד להיכנס.
- ***מוניטור:*** מבנה שעוטף מבנה נתונים אחר (שיכול להיות מורכב - למשל מערך + כמה משתנים), וגם עוטף פעולות על מבנה הנתונים הזה. ת'רדים שנכנסים לתוך המוניטור יכולים לעשות wait() כדי לאפשר לת'רדים אחרים להיכנס למוניטור. ת'רדים אחרים בתוך המוניטור יכולים אחרי זה לעשות signal() כדי להעיר ת'רד אחד שעשה wait() או לעשות broadcast() כדי להעיר את כל הת'רדים שעשו wait. בנוסף אפשר לעשות wait() לכמה דברים שונים.


> [!question]- אלגוריתם Peterson (1981)
> ```c
> // Peterson Algorithm (1981) (For 2 thread mutual exclusion)
flag[i] = True; // Set intent
turn = 1 - i; // Set turn to other thread
while(flag[1-i] and turn==1-i); // While other thread has intent and turn, wait.
// Critical section
flag[i] = False;
> ```


> [!question]- אלגוריתם המאפייה
> - כל ת'רד לוקח מספר. אם המספר גדול מהמספר של כל הת'רדים האחרים ממשיך לאיזור הקריטי, אחרת מחכה.
> - אבל זה יוצר בעיה - עם קונטקסט סוויץ' בזמן המתאים שני ת'רדים יכולים לקבל את אותו מספר.
> - אז מוסיפים גם דגל שאומר אם תהליך נמצא בשלב הבחירה. אם תהליך כלשהו נמצא בשלב הבחירה, אז שום תהליך לא ימשיך לאיזור הקריטי.


> [!question]- Mutual Exclusion w/ Semaphore
> - Down(S)
> - Critical Section
> - Up(S)


> [!question]- בעיית הפילוסופים
> - הפילוסופים יושבים במעגל וכל פילוסוף צריך את הצ'ופסטיק הימני והשמאלי כדי לאכול. איך קובעים אילו צ'ופסטיקס ירימו כדי למנוע דדלוק?
> - כל אחד מהפילוסופים 1 עד n-1 מנסה להרים את הימני. ולאחר מכן את השמאלי.
> - הפילוסוף ה-n מנסה קודם את השמאלי ואז את הימני.
> - אפשרות אחרת היא שהזוגיים ירימו את הימני ואז את השמאלי, והאי זוגיים ירימו את השמאלי ואז את הימני.


> [!question]- בעיית הבאפר החסום (Producer Consumer)
> - ריק


> [!question]- בעיית הקוראים והכותבים
> - ריק


---
## 5 - תזמון
- ***זמן המתנה/Wait TIme:*** הזמן שעבודה ממתינה מהרגע שמקבלים אותה.
- ***זמן ריצה/Run Time:*** הזמן שלוקח לעבודה לרוץ.
- ***זמן תגובה/Response time/Turnaround Time:*** זמן המתנה + זמן ריצה
	- לעיתים מתייחסים ל-Response time כזמן משהג'וב הגיע עד שהוא **מתחיל.**
- ***אלגוריתמי תזמון Offline:*** כל העבודות נתונות מהתחלה. לעומת אונליין שבהם העבודות מגיעות בזמן אמת.
- ***ת'רופוט/Throughput:*** כמות עבודות שהסתיימו ליחידת זמן. זה לא קריטי במקרה ה-Offline. קונטקסט סוויטצ'ים רבים יורידו את זה.
- ***ניצולת:*** זמן ריצה אשכרה חלקי (זמן ריצה אשכרה ועוד קונטקסט סווצ'ים ועוד זמן איידל).
- **מקדם השונות/Coefficient of Variation:** סטטיסטיקה על העבודות שמגיעות. מוגדרת כך: $CV = \frac{std}{mean}$
- אם ה-CV של התפלגות אורכי העבודות גדול מ-1, אז ככל שהעבודה רצה ליותר זמן, נשאר לה גם יותר זמן לרוץ (בממוצע). זה מה שנקרא התפלגות שהיא Heavy Tail. והתפלגות כזו היא לרוב מה שבאמת רואים.
- ***מערכת פתוחה לעומת סגורה:*** במערכת "פתוחה" כמות העבודות משתנה וה-Load בדר"כ קטן מ-100%. (לדוגמא שרת אינטרנט). במערכת סגורה יש כמות קבועה של עבודות בתור, וכשהן מסתיימות אותן עבודות חוזרות לתור ואפשר להשתמש בפידבק מהן כדי ללמוד. והעומס בדר"כ 100%. בפועל רוב המערכות הן שילוב של שני הדברים.
- **משפט ליטל:** בהקשר שלנו, אומר שהמספר הממוצע של תהליכים במערכת שווה לקצב ההגעה שלהם, מוכפל בזמן הממוצע בו הם קיימים במערכת.

נרצה לתאר אלגוריתמי תזמון שמקטינים את זמן התגובה המתנה הממוצע, זמן התגובה הממוצע, ואת ה-Throughput. (ומגדילים את הניצולת)

###### אופליין:

> [!question]- תזמון First Come First Serve (FCFS) - אופליין
> - על פי הסדר שהעבודות באו


> [!question]- תזמון Shortest Job First (SJF) - אופליין
> - על פי האורך של העבודות
> - הערה: זה האלגוריתם האופטימלי לזמן ההמתנה ולזמן התגובה הממוצע במקרה האופליין כשאנחנו יודעים את אורכי העבודות מראש.

###### אונליין:

> [!question]- תזמון First Come First Serve (FCFS) - אונליין
> - על פי הסדר שהעבודות באו


> [!question]- תזמון Shortest Job FIrst (SJF) - אונליין
> - על פי האורך של העבודות


> [!question]- תזמון Shortest Remaining Processing Time (SRPT)
> - על פי האורך **הנותר** של העבודות.
> - משתמשים פה ב-Preemption, כלומר יכולים לעצור עבודה באמצע.
> - עדיין מניח שאנחנו יודעים את זמני הריצה של העבודות


> [!question]- תזמון Round Robin (RR)
> - מריצים תהליכים למשך קוונטום קצר וקבוע מראש ואז מזיזים אותם לסוף התור. (ממומש על ידי פסיקות של השעון)
> -  - זה טוב כי כשיש המון שונות באורכי העבודות בדרך כלל. (גם קצרות וגם ארוכות) כלומר $CV > 1$.


> [!question]- תזמון Multi Level Feedback Queue (MLFQ)
> - כמו RR אבל יש כמה תורים ולכל תור יש קוואנטום. כשעבודה מסיימת קוואנטום (או כמות קוונטומים) והיא עוד לא הסתיימה היא עוברת לתור עם קוונטום ארוך יותר.
> - אבל יש עדיפות לעבודות בתורים עם קוונטום נמוך יותר.
> - יש הרעבה. פתרונות:
> 	- להקצות לכל תור זמן אחוז זמן CPU
> 	- לתת לכל ג'וב עדיפות, שעולה ככל שהוא לא רץ יותר זמן.
> 	- להסתכל על זה בתור פיצ'ר. אם כל הזמן מגיעות עבדוות קצרות המערכת באוברלאוד בכ"מ.


> [!question]- תזמון EASY ו-Backfilling
> - רלוונטי למחשבי על ומערכות עם הרבה CPUים.

---
## 6 - רשתות (תרגול)

- ב-UDP סוקט אחד יכול לקבל מכמה יוזרים, אבל ב-TCP פותחים סוקט חדש לכל אחד.

```c
///////////////////////
// server and client //
///////////////////////
socket() // create a socket
close() // close a socker
read() / recv() // read from a socket (like a file)
write() / send() // write to a socket (like a file)

////////////
// server //
////////////
bind() // bind a socker to a port and address to listen to locally (i.e. listen to wifi, ethernet, etc (usually this can be all))
listen() // sets a socket to listening mode to allow it to accept connections.
accept() // a blocking call, returns a file descriptor of a new socket if there was a successful incoming connection

////////////
// Client //
////////////
connect() // connect to server by address and port
```

---
## 7 - ניהול זיכרון, פייג'ינג
- פעולת ה-Caching עוזרת בגלל לוקאליות טמפורלית ומרחבית.
- ה-L1 וה-L2 פרטיים לכל מעבד, L3 משותף לכל המעבדות.
- כשמקמפלים תכנית עדיין אין בה כתובות. כלומר המשתנים הם עם השמות שלהם. כמריצים אותה ה-***Loader*** של מערכת ההפעלה שטוען את התכנית לזיכרון (וספריות שהוא משתמש בהן), אז בחלק הטקסט בזיכרון של התכנית יש כתובות לוגיות.
- ***תרגום כתובת לוגית לכתובת פיזית:*** מתבצע על ידי רכיב ה-Memory Management Unit (MMU) (שהוא פיזי בתוך "חבילת ה-CPU") והוא שולח את הכתובות הפיזית לזיכרון כדי לכתוב/לקרוא. יש כמה גישות לתרגום.
- ***פרגמנטציה חיצונית/External Fragmentation:*** כשקיים מספיק זיכרון פנוי לתכנית חדשה אבל הוא לא רציף.
- ***פרגמנטציה פנימית/Internal Fragmantation:*** השטח המבוזבז בין ה-Stack ל-Heap.
- **אקספשן Page Fault:*** קורא כשדף שמבקשים לא בזיכרון (Valid Bit = 0), ה-OS מתמודדת איתו על ידי כך שהיא אומרת לדיסק לטעון לפריים ריק את הדאטא, ואז הדיסק שם אותו בזיכרון, עושה interrupt, ומערכת ההפעלה מעדכנת את ה-Valid bit להיות 1 וכותבת את הפריים.


> [!question]- גישת Base + Bound
> - אם x זו הכתובת הלוגית, אז הכתובת הפיזית זה x+base.
> - כל המרחב הלוגי חייב להיות ממופה בזיכרון הפיזי.
> - מה שמערכת ההפעלה מחליטה היא מה יהיה ה-Base וה-Bound של כל תכנית, איפה היא תמופה. אלגוריתמי בחירה:
> 	- אלגוריתם Best Fit: מוצא את האיזור הרציף הקטן ביותר בזיכרון שיכול להכיל את התכנית.
> 	- אלגוריתם First Fit: מוצא את האיזור הרציף הראשון בזיכרון שיכול להכיל את התכנית.
> 	- אלגוריתם Next Fit: כמו First Fit, אבל מתחיל מהנקודה שהוא סיים בפעם שעברה במקום מהתחלה כל פעם.
> - יוצר External Fragmantation.
> 	- אפשר לעשות ***Compaction*** כדי למנוע את זה אבל זו פעולה יקרה.


> [!question]- גישת סגמנטציה (תרגול)
> - כמו Base+Bound אבל עם הרבה בייסים ובאונדים.
> - לכל תהליך יש טבלת סגנטים שאומרת איפה הזיכרון שלו.


> [!question]- גישת Paging
> - מחלקים את מרחב הכתובות הלוגי לפייג'ים של 4KB (2^12B) ומחלקים את המרחב הפיזי ל-Frames באותו גודל. הפייג'ים ממופים לפריימים על ידי מערכת ההפעלה וה-MMU.
> - לכל תהליך יש ***Page Table*** שבו כתוב הפריים של כל פייג'. ה-MMU משתמש בו כדי לתרגם. כשעושים קונטקסט סוויטצ' הפייג' טייבל מוחלף.
> - תרגום: בהינתן כתובת לוגית כלשהי, $log_2(psize)$ קובע את כמות הבייטים ב-Offset (כלומר הבייטים הקטנים שרק אומרים לנו איפה אנחנו בתוך הפריים). שאר הבייטים הם האינדקס של ה-Page, כלומר נכניס אותם לפייג' טייבל ונחליף אותם בתוצאה.
> 	- ***באפר התרגום/TLB/Translation Lookaside Buffer:*** רכיב ב-CPU שמשמש בתור Cache לתרגומים האחרונים שנעשו (אותו מבנה כמו הפייג' טייבל: אינדקס פייג' -> אינדקס פריים)
>- מערכת ההפעלה שומרת רשימה של פריימים פנויים.


> [!question]- גישת Demand Paging
> - לא לשמור תמיד את כל הפייג'ים בזיכרון.
> - להוסיף ל-Page Table עמודת Valid Vit (V) עם ביט שמציין האם הדף בזיכרון (1=כן, 0=לא).
> - מערכת ההפעלה טוענת את הדף לזיכרון רק כשצריך אותו.
> - אפשר גם לעשות ***Pre-Paging***, כלומר לתת למערכת ההפעלה לנחש אילו דפים התהליך יצטרך ולטעון אותם מראש. יכול להיות טוב אם מנחשים נכון.
> - מה אם ה-RAM מלא?. כאן נכנסים לתמונה Page Eviction Algorithms.

#### אלגוריתמי החלפת פייג'ים / Page Replacement Algorithms
- משתמשים בהם כאשר אין פריים חופשי למפות אליו Page. הם בוחרים איזה פייג' להעיף.
- ***החלפת עמוד/Page Eviction:***
	1. מעתיקים את הדאטא החדש לדיסק אם הוא שונה
	2. משתמשים בפריים החופשי לעמוד חדש.
- ***קורבן/Victim:*** העמוד שעושים לו Eviction.
- ***סט העבודה/Working Set:*** קבוצת הדפים שתכנית מסויימת משתמשת בהם ברגע נתון. נרצה להעריך מהי כדי שלא לעשות להם Eviction.


> [!question]- האלגוריתם האופטימלי/Belady's Algorithm (Infeasible)
> - בוחרים את העמוד שלא נשתמש בו לזמן הארוך ביותר.
> - לא פיזבילי במציאות, בפועל אנחנו רק יכולים להעריך את הזמן הנותר.


> [!question]- Random Replacement
> - לבחור את הקורבן באופן אקראי.


> [!question]- First In First Out (FIFO)
> - לשמור רשימה מקושרת ממוינת של הדפים על פי הסדר שהם נטענו לזיכרון, תמיד לבחור את הקורבן להיות הדף הכי זקן.
> - בעייתי בגלל ***אנומיליית בלאדי/Belady's Anomaly:***
> 	- נצפה שככל שיש יותר זיכרון, יהיו פחות Page Faults. בפועל זה לא המצב, ויותר זיכרון גורר **יותר** Page faults!

באלגוריתמים הבאים, נניח כי יש ב-Page Table שני ביטים נוספים (ואכן יש אותם במעבדים מודרניים בפייג' טייבל עצמו). ה-MMU מנהל אותם:
- ***ביט הרפרנס/Reference bit:*** נדלק כשניגשים לדף.
- ***הביט המלוכלך/Dirty bit:*** נדלק כשכותבים לדף.

> [!question]- Not Recently Used (NRU)
> - באופן מחזורי, מערכת ההפעלה מנקה את ה-Reference bits.
> - כשיש Page Fault וצריך לעשות Eviction, נבחר פייג' שהרפרנס ביט שלו הוא 0.
> - משמש כהערכה גסה של LRU.


> [!question]- Least Recently Used (LRU)
> - נשמור לכל פייג' Timestamp שאומר מתי ניגשו אליו בפעם האחרונה.
> - כשיש Page Fault וצריך לעשות Eviction, נמצא את הדף הישן ביותר.
> - זה מוסיף **אוברהד משמעותי!**


> [!question]- אלגוריתם השעון / The Clock Algorithm / Second Chance Algorithm
> - מארגנים את הפריימים במעגל, עם יד של שעון שמצביעה על אחד מהם.
> - לכל פייג' יש רפרנס ביט.
> - ברגע שצריך לעשות Eviction, נבדוק את העמוד שהיד מצביעה עליו ונפעל כך:
> 	- אם יש לו 1 ב-reference bit, קבע אותו להיות 0 ותמשיך.
> 	- תעשה Evict לראשון שיש לו 0.
> - אם מפנים לא חוזרים להתחלה אלא ממשיכים מהעמוד הבא.

> [!question]- אלגוריתם WSclock
> - מארגנים את הפריימים במעגל, עם יד של שעון שמצביעה על אחד מהם.
> - לכל פייג' יש רפרנס ביט. וגם שומרים את הזמן האחרון שניגשנו אליו.
> - ברגע שצריך לעשות Eviction, נבדוק את העמוד שהיד מצביעה עליו ונפעל כך:
> 	- אם R=1, קבע R=0, עדכן את זמן השימוש האחרון והמשך.
> 	- אם R=0 וההפרש בין זמן השימוש האחרון לזמן הנוכחי קטן מ-k כלשהו, המשך.
> 	- אחרת, כלומר אם R=0 וההפרש גדול, תעשה Evict.

- נשים לב שעדיף לעשות Evict לדף שהוא לא Dirty, כי לא צריך לכתוב חזרה לדיסק את השינויים.
- אפשר לבחור אם רוצים **Local Paging**, לפיה אם P1 גורם ל-Page Fault, נעשה Eviction רק לדפים של P1, לעומת **Global Paging**, לפיו נעשה Eviction לכל דף.
- יש דרך לחשב את ההאטה על פי הסיכוי לPage Fault.

#### מבנה טבלת הדפים
- לרוב זה לא פרקטי להשתמש בטבלת דפים סטנדרטית כי היא לוקחת יותר מדי מקום בזיכרון

> [!question]- טבלת דפים היררכית / Hierarchical Page Table
> - במקום להשתמש בטבלה אחת ענקית, נשתמש במבנה של עץ, כלומר טבלאות שמצביעות לטבלאות אחרות, ואז הטבלאות בעלים הן אלו שיכילו את האינדקס של הפריים.
> - בדרך כלל נרצה שכל טבלה תמלא בדיוק פריים אחד. כלומר אם גודל של פריים הוא $4KB = 2^12B$, אז הגודל של ה-Offest הוא 12, ואם גודל של פוינטר הוא $4B$ אז כל טבלה תכיל $2^10$ פוינטרים, כלומר אם יש 32 ביט, 10 הביטים השמאליים יהיו לטבלה הראשונה, 10 הביטים האמצעיים לטבלה השנייה ו-12 הביטים שנותרו ל-Offset.
> - מה שטוב בזה זה שלא חייבים שכל טבלאות הביניים יהיו בזיכרון או אפילו באחסון.


> [!question]- Hashed Page Table
> - ממומש כטבלת גיבוב מפייג' לפריים.
> - יכולות להיות התנגשויות וצריך לטפל בהן עם רשימה מקושרת.


> [!question]- Inverted Page Table
> - נועד למקרים בהם הזיכרון ממש קטן.
> - טבלת דפים אחת **לכל התהליכים**.
> - ממפה פריימים לדפים + pid. (האינדקס ברשימה הוא הפריים).
> - כשרוצים לשלוף דף, מחפשים בכל הרשימה.


####  מרחק סטאק ו-Thrashing
- נרצה למדוד את הלוקאליות בשימוש בזיכרון.
	- לשם כך נשתמש בסטאק. כשנקרא את הכתובת x בזיכרון, נבדוק את המרחק של במורד הסטאק של הקריאה האחרונה של הכתובת x (אם אין כזו המרחק הוא אינסוף ונוסיף את x לסטאק). אם יש כזו נשמור את המרחק ונזיז את x למעלה הסטאק.
- מספיק להסתכל על מרחקי הסטאק כדי לחשב ביצועים בשיטת LRU.

- ***ת'ראשינג/Thrashing:*** תופעה שמתקיימת כאשר יש יותר מדי multiprogramming. ככל שמעלים את כמות התכניות ה-CPU usage עולה ועולה עד שמגיעים לנקודה שהוא יורד בחדות. זה בגלל שעבור כל context switch צריך לעשות המון החלפות פייג'ים וזו פעולה איטית יחסית.
	- **מתי זה קורה?** כשגודל הכולל של כל ה-Working Sets גדול מגודל הזיכרון!
	- **פתרון:** להוסיף מצב חדש לתהליכים: swapped - שזה כולל להעביר אותם לזיכרון - תזמון לטווח ארוך!. יכול להיות Ready Swapped או Blocked Swapped.
---
## 8 - מערכות I/O (תרגול)
- שיטת RAID-0 - חלוקה של המידע בין דיסקים שונים.
- שיטת RAID-1 (Mirroring) - לכל דיסק שומרים העתק שנקרא Mirror.
- שיטת RAID-4 (Parity) - יש דיסק אחד שמכיל XOR של הדאטא בכל הדיסקים אחרים. אז אם דיסק אחד נכשל אפשר להציל את המידע בעזרת תכונת ה-XOR.
- **תהליך Booting:*** איך מאתחלים את מערכת ההפעלה, ה-BIOS שהוא קוד Firmware שמגיע עם החומרה עצמה קורא את הקוד ב-Master Boot Record(MBR) שנמצא בסקטור 0, של הדיסק. הקוד הזה מאתחל את מערכת ההפעלה. אם יש MultiBooting עם כמה מחיצות מה שקובע איזו מערכת הפעלה נפעיל זה המחיצה שה-BIOS בוחר, שהוא קורא את ה-MBR שלה.

---
## 9 - מערכות קבצים

- ***הארד לינק/Hard Link:*** כאשר שני נתיבים מצביעים על אותו תוכן. אי אפשר לעשות הארד לינק על תיקייה כדי להימנע ממעגלים.
	- יש להם שתי תכונות: Move safe, Delete safe - אפשר להזיז ולמחוק ולא לקבל לינקים שבורים.
- ***סופט לינק/Soft Link/Symbolic Link:*** "קיצור דרך" - קובץ שמכיל קישור לקובץ או תיקייה אחרת.
	- לא Move safe ולא delete safe.
- הרשאות גישה
- קבצים מחולקים לבלוקים (בדרך כלל 4KB, כמו Pages, Frames)
- ***סופרבלוק/Superblock:*** מבנה נתונים שנמצא בRAM ומכיל רשימה חלקית של הבלוקים שפנויים (באחסון) ושל inodes שפנויים ב-inode table (באחסון).

- דרכים לארגן בלוקים:
	- רשימה מקושרת - כל בלוק יכיל פוינטר לבלוק הבא בקובץ
	- טבלת הקצאת קבצים/File Allocation Table(FAT) - לשמור בזיכרון טבלה עם פוינטרים לבלוקים של כל הקבצים.
	- ***מה בפועל בלינוקס - INODE.***

####  ארגון inode
- בלינוקס יש inodes, כל אחד בגודל 256B. הוא מכיל מטא-דאטא על הקובץ, 12 דיירקט פוינטרים לבלוקים עם התוכן של הקובץ, single indirect, double indirect, triple indirect. שמצביעים לבלוקים שמצביעים לבלוקים.
- רוב הקבצים בלינוקס הם קטנים ותופסים רק את 12 הפוינטרים הראשונים.
- בפועל כשניגשים לindirect ברצף שומרים אותם ל-***Buffer Cache*** לפונטרים של הבלוקים באמצע וכך חוסכים גישות.
- אפשר גם לעשות inlineing ב-inode ולשמור את התוכן ישר במקום של הפונטרים אם הוא קצר.

- ***טבלת inode table:*** כל ה-inodes שנמצאים בדיסק.
- ***טבלת vnode table:*** נמצאת ב-RAM, מכילה את כל ה-inodes של הקבצים הפתוחים כרגע.

לסיכום יש שלושה טבלאות שנוגעות לקבצים:
1. בתוך ה-PCB, יש **לכל קובץ** רשימה של ה-file descriptors של הקבצים הפתוחים שלו. ממפה מ-fd ל-Open File Description Table. (לכל קובץ ה-fd פרטיים כלומר ייתכן ששני קבצים יפתחו קבצים שונים שיקבלו את אותו fd).
2. ה-***Open File Description Table:*** זו טבלה אחת גדולה שמשותפת לכל מערכת ההפעלה, וממפה בין כל קובץ פתוח לפוינטר של ה-inode שלו בטבלת ה-vnode. בנוסף כל entry מכיל reference count של כמות ה-PCB שמצביעים עליו. מכיל גם את המיקום בקובץ. (רלוונטי ל-fork). (יכולים להיות כמה עבור קובץ אחד)
3. ***טבלת ה-vnode:*** גם היא משותפת לכל מערכת ההפעלה ומכילה את ה-inodes של הקבצים הפתוחים. (כל קובץ פה יופיע לכל היותר פעם אחת).